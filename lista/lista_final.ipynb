{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação manual de bibliotecas\n",
    "!pip install numpy matplotlib pandas seaborn prettytable\n",
    "# Bibliotecas\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "import prettytable as pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Considere a base de dados Breast Cancer Wisconsin (Diagnostic) (baixar em http://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic). Remova a coluna ID da base de dados e separe a coluna de Diagnosis. Divida a base de dados: 70% das primeiras amostras serão o conjunto de treinamento e os restantes 30% serão usados para teste. Faça:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura inicial e cinsiderações gerais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura Inicial\n",
    "# data_raw = pd.read_csv('wdbc.data', header = None, names=feature_names)\n",
    "data_raw = pd.read_csv('wdbc.data', header = None)\n",
    "data_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados é dividido em 3 faixas:\n",
    "- 2 - 11: médio (da imagem)\n",
    "- 12 - 21: desvio padrão (da imagem)\n",
    "- 22 - 31: pior valor (da imagem)\n",
    "\n",
    "Observe que a coluna 1 é a saída (diagnóstico), e a coluna 0 é um número de identificação irrelevante, que será removido dos dados.\n",
    "Como não conhecemos a priori a influência do desvio padrão da imagem e do pior valor do atributo no diagnóstico, não iremos segmentar os dados.\n",
    "Em vez disso, trataremos todos os 30 atributos como se fossem atributos comuns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removemos a coluna de ID do conjunto de dados, pois ele não é relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo atributo irrelevante\n",
    "data_slice_no_id = data_raw.loc[:,1:31]\n",
    "data_slice_no_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renomeamos a primeira coluna para 'class'. Ela contém a saída, ou seja, o disgnóstico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia algumas colunas\n",
    "data = data_slice_no_id.rename({1:'class'}, axis=1)\n",
    "data\n",
    "# print(data[4].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Com os dados de treinamento, calcule os valores de média e desvio padrão de cada atributo para cada classe. Organize os valores em uma tabela. Comente os valores observados.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos o cabeçalho das tabelas:\n",
    "\n",
    "mean_names = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "se_names = ['radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se']\n",
    "edge_names = ['radius_edge', 'texture_edge', 'perimeter_edge', 'area_edge', 'smoothness_edge', 'compactness_edge', 'concavity_edge', 'concave_points_edge', 'symmetry_edge', 'fractal_dimension_edge']\n",
    "mean_names.extend(se_names)\n",
    "mean_names.extend(edge_names)\n",
    "feature_names = ['class']\n",
    "feature_names.extend(mean_names)\n",
    "\n",
    "# define faixa dos dados que são os atributos (exclui a classe)\n",
    "faixa = np.arange(1,31)\n",
    "\n",
    "# Extrai todos os valores únicos de classe e os coloca num vetor\n",
    "classes = data['class'].unique()\n",
    "\n",
    "# cria tabelas\n",
    "tabela1 = pt.PrettyTable()\n",
    "tabela2 = pt.PrettyTable()\n",
    "\n",
    "# Adiciona cabeçalho às tabelas:\n",
    "tabela1.field_names = feature_names\n",
    "tabela2.field_names = feature_names\n",
    "\n",
    "# Imprime a tabela de média\n",
    "print(f\"Média de cada classe:\\n\")\n",
    "for i in range(0,classes.size):\n",
    "    data_select = data[data['class'] == classes[i]]\n",
    "\n",
    "    # Calcula média\n",
    "    data_slice = data_select.iloc[:,faixa].mean()\n",
    "    data_slice = data_slice.round(4)\n",
    "    \n",
    "    # Formata dados em linha da tabela\n",
    "    row = list(classes[i])\n",
    "    row.extend(data_slice)\n",
    "    # Adciiona linha à tabela\n",
    "    tabela1.add_row(list(row))\n",
    "print(tabela1)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Imprime a tabela de variância:\n",
    "print(f\"Variância de cada classe:\")\n",
    "for i in range(0,classes.size):\n",
    "    data_select = data[data['class'] == classes[i]]\n",
    "\n",
    "    # Calcula média e arredonda para 4 casas decimais \n",
    "    data_slice = data_select.iloc[:,faixa].var()\n",
    "    data_slice = data_slice.round(6)\n",
    "    \n",
    "    # Formata dados em linha da tabela\n",
    "    row = list(classes[i])\n",
    "    row.extend(data_slice)\n",
    "    # Adciiona linha à tabela\n",
    "    tabela2.add_row(list(row))\n",
    "print(tabela2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparando os valores de médias e variâncias com os dados, pode-se observar que para os atributos 'perimeter_mean' e 'area_mean', a variância superior à média, por um fator de 4 vezes e 1000 vezes respectivamente para amostras Malignas, e cerca de 2 vezes e 40 vezes respectivamente para amostras Benignas. \n",
    "- Em geral, os valores médios dos atributos de amostras Malignas são *um pouco maiores* do que os de amostras Benignas, tanto média quanto variância. As exceções são 'fractal_dimension_mean', 'texture_se' e 'symmetry_se', onde os valores das amostras Malignas são muito próximos ou menores que os das amostras Benignas. \n",
    "- A variância dos valores dos atributos de amostras Malignas são em geral *um pouco maiores* que o de amostras benignas, com exceção de 'texture_mean', 'smoothness_mean', 'texture_se', 'smoothness_se', 'concavity_se', 'concave_points_se', 'fractal_dimension_se', 'texture_edge' e 'smoothness_edge', em que os valores são próximos ou menores.\n",
    "\n",
    "- Os dados de média foram arredondados para 4 casas decimais (tal qual foram fornecidos os dados de entrada). A variância foi colocada em 6 casas decimais, pois alguins valores eram demasiado pequenos em magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Visualize os dados de treinamento usando o t-SNE (pode usar o código pronto). Comente o gráfico obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "from tsne import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\n",
      "        2      3       4       5       6       7       8       9       10  \\\n",
      "0    17.99  10.38  122.80  1001.0  0.1184  0.2776  0.3001  0.1471  0.2419   \n",
      "1    20.57  17.77  132.90  1326.0  0.0847  0.0786  0.0869  0.0702  0.1812   \n",
      "2    19.69  21.25  130.00  1203.0  0.1096  0.1599  0.1974  0.1279  0.2069   \n",
      "3    11.42  20.38   77.58   386.1  0.1425  0.2839  0.2414  0.1052  0.2597   \n",
      "4    20.29  14.34  135.10  1297.0  0.1003  0.1328  0.1980  0.1043  0.1809   \n",
      "..     ...    ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "564  21.56  22.39  142.00  1479.0  0.1110  0.1159  0.2439  0.1389  0.1726   \n",
      "565  20.13  28.25  131.20  1261.0  0.0978  0.1034  0.1440  0.0979  0.1752   \n",
      "566  16.60  28.08  108.30   858.1  0.0846  0.1023  0.0925  0.0530  0.1590   \n",
      "567  20.60  29.33  140.10  1265.0  0.1178  0.2770  0.3514  0.1520  0.2397   \n",
      "568   7.76  24.54   47.92   181.0  0.0526  0.0436  0.0000  0.0000  0.1587   \n",
      "\n",
      "         11  ...      22     23      24      25      26      27      28  \\\n",
      "0    0.0787  ...  25.380  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
      "1    0.0567  ...  24.990  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
      "2    0.0600  ...  23.570  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
      "3    0.0974  ...  14.910  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
      "4    0.0588  ...  22.540  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
      "..      ...  ...     ...    ...     ...     ...     ...     ...     ...   \n",
      "564  0.0562  ...  25.450  26.40  166.10  2027.0  0.1410  0.2113  0.4107   \n",
      "565  0.0553  ...  23.690  38.25  155.00  1731.0  0.1166  0.1922  0.3215   \n",
      "566  0.0565  ...  18.980  34.12  126.70  1124.0  0.1139  0.3094  0.3403   \n",
      "567  0.0702  ...  25.740  39.42  184.60  1821.0  0.1650  0.8681  0.9387   \n",
      "568  0.0588  ...   9.456  30.37   59.16   268.6  0.0900  0.0644  0.0000   \n",
      "\n",
      "         29      30      31  \n",
      "0    0.2654  0.4601  0.1189  \n",
      "1    0.1860  0.2750  0.0890  \n",
      "2    0.2430  0.3613  0.0876  \n",
      "3    0.2575  0.6638  0.1730  \n",
      "4    0.1625  0.2364  0.0768  \n",
      "..      ...     ...     ...  \n",
      "564  0.2216  0.2060  0.0712  \n",
      "565  0.1628  0.2572  0.0664  \n",
      "566  0.1418  0.2218  0.0782  \n",
      "567  0.2650  0.4087  0.1240  \n",
      "568  0.0000  0.2871  0.0704  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "Preprocessing the data using PCA...\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 569...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/tsne.py:28: RuntimeWarning: divide by zero encountered in log\n",
      "  H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
      "/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/tsne.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
      "/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/tsne.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  P = P / sumP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing P-values for point 500 of 569...\n",
      "Mean value of sigma: 22.041685\n",
      "Iteration 10: error is nan\n",
      "Iteration 20: error is nan\n",
      "Iteration 30: error is nan\n",
      "Iteration 40: error is nan\n",
      "Iteration 50: error is nan\n",
      "Iteration 60: error is nan\n",
      "Iteration 70: error is nan\n",
      "Iteration 80: error is nan\n",
      "Iteration 90: error is nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/lista_final.ipynb Cell 17\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/lista_final.ipynb#Y115sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/lista_final.ipynb#Y115sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m n_collumns \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/lista_final.ipynb#Y115sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m Y \u001b[39m=\u001b[39m tsne(X, \u001b[39m2\u001b[39;49m, n_collumns, \u001b[39m20.0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/harmonia/codes/machine-learning-laboratory-2023-2/lista/lista_final.ipynb#Y115sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m Y \u001b[39m=\u001b[39m tsne(X, \u001b[39m2\u001b[39m, \u001b[39m20.0\u001b[39m)\n",
      "File \u001b[0;32m~/codes/machine-learning-laboratory-2023-2/lista/tsne.py:155\u001b[0m, in \u001b[0;36mtsne\u001b[0;34m(X, no_dims, initial_dims, perplexity)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m# Compute gradient\u001b[39;00m\n\u001b[1;32m    154\u001b[0m PQ \u001b[39m=\u001b[39m P \u001b[39m-\u001b[39m Q\n\u001b[0;32m--> 155\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(n):\n\u001b[1;32m    156\u001b[0m     dY[i, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mtile(PQ[:, i] \u001b[39m*\u001b[39m num[:, i], (no_dims, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT \u001b[39m*\u001b[39m (Y[i, :] \u001b[39m-\u001b[39m Y), \u001b[39m0\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39m# Perform the update\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\")\n",
    "\n",
    "# Coloca dados de entrada sem a coluna de classes\n",
    "X = data.iloc[:,faixa]\n",
    "print(X)\n",
    "n_collumns = data.shape[1] - 1\n",
    "\n",
    "\n",
    "Y = tsne(X, 2, n_collumns, 20.0)\n",
    "Y = tsne(X, 2, 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plota os gráficos\n",
    "scatter = plt.scatter(Y[:, 0], Y[:, 1], 20, data.iloc[:,0])\n",
    "\n",
    "# Produz legenda com cores únicas a partir do scatterplot\n",
    "legend1 = ax.legend(*scatter.legend_elements(), loc=\"lower left\", title=\"Classes\")\n",
    "\n",
    "plt.title(\"Projeção 2D usando T-SNE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Com os dados de treinamento, use o coeficiente de correlação para remover atributos redundantes (considere atributos redundantes atributos com coeficiente maior ou igual a 0,9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Com os dados de treinamento, use informação mútua entre os atributos restantes de entrada e o atributo de saída e selecione os 10 melhores atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e) Treine e teste os algoritmos com os atributos selecionados: Rocchio (com distância Euclidiana), kNN (com distância Euclidiana) e Naive Bayes (considere que os atributos tenham distribuição Gaussiana). Para selecionar o melhor valor de k, divida os dados de treinamento em treinamento e em validação. Explique as considerações realizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f) Mostre os resultados sobre o conjunto de teste na forma de matriz de confusão, e com as métricas Recall, Precisão e Acurácia (a classe positiva é a maligna) e compare os resultados entre os classificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g) Realize os passos e) e f), mas usando agora todos os atributos (com exceção do ID). Compare os resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h) Faça um relatório explicando as decisões escolhidas, apresentando os resultados e os códigos usados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
